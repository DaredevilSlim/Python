#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from datetime import datetime

# https://ru.hexlet.io/courses/basic-algorithms/lessons/algorithm-complexity/theory_unit


# Алгоритмическая сложность
# В программировании используются алгоритмы, которые по-разному решают одну и ту же задачу: например, сортировку
# массива. При этом алгоритмы работают с разной скоростью и требуют разное количество памяти. При прочих равных условиях
# мы бы выбрали быстрый или нетребовательный алгоритм.
# Чтобы правильно выбирать алгоритмы, нужно научиться сравнивать их, чем мы и займемся в этом уроке. Мы познакомимся с
# двумя основными способами, разберем их плюсы и минусы. Опираясь на эти способы, мы сравним время работы уже знакомых
# нам алгоритмов.


# Как оценить скорость алгоритма.
# Скорость алгоритмов можно сравнивать самым очевидным способом — физически измерить время выполнения на одних и тех же
# данных. Чтобы сравнить сортировку выбором и быструю сортировку, мы можем взять массив из нескольких элементов и
# измерить время быстрой сортировки:
def quick_sort(items):
    def partition(items, left, right, pivot):
        while True:
            while items[left] < pivot:
                left += 1
            while items[right] > pivot:
                right -= 1
            if left >= right:
              return right + 1
            items[left], items[right] = items[right], items[left]
            left += 1
            right -= 1
    def quick_sort(items, left, right):
        length = right - left + 1
        if length < 2:
            return
        pivot = items[left]
        split_index = partition(items, left, right, pivot)
        quick_sort(items, left, split_index - 1)
        quick_sort(items, split_index, right)
    quick_sort(items, 0, len(items) - 1)
    return items


items = [86, 66, 44, 77, 56, 64, 76, 39, 32, 93, 33, 54, 63, 96, 5, 41, 20, 58, 55, 28]
start = datetime.now()
quick_sort(items)
end = datetime.now()
print(end - start)  # <= 0.20 миллисекунд
print(quick_sort(items))  # [5, 20, 28, 32, 33, 39, 41, 44, 54, 55, 56, 58, 63, 64, 66, 76, 77, 86, 93, 96]
# Алгоритм быстрой сортировки мы уже разбирали. Единственное, что нам пока не встречалось — вызов метода
# datetime.now().
# datetime — это объект в глобальной области видимости, который используют для измерения производительности.
# Метод now() возвращает количество миллисекунд с момента старта браузера. Можно запустить этот метод, сохранить
# значения до запуска кода и после его завершения, и вычесть одно из другого — и тогда мы узнаем, сколько миллисекунд
# работал наш код.
# Чтобы сравнить два алгоритма, надо упорядочить точно такой же массив с помощью алгоритма выбора:


def selection_sort(items):
    for i in range(len(items) - 1):
        index_min = i
        for j in range(i + 1, len(items) - 1):
            if items[j] < items[index_min]:
                index_min = j
        items[i], items[index_min] = items[index_min], items[i]
    return items


items = [86, 66, 44, 77, 56, 64, 76, 39, 32, 93, 33, 54, 63, 96, 5, 41, 20, 58, 55, 28]
start = datetime.now()
selection_sort(items)
end = datetime.now()
print(end - start)  # <= 0.09 миллисекунды
print(selection_sort(items))
# Оценим скорость кода выше:
# Быстрая сортировка — 0,20 миллисекунд
# Сортировка выбором — 0,09 миллисекунд
# Результат выглядит странно. Раз уж быструю сортировку назвали быстрой, то время ее выполнения должно быть меньше, чем
# у сортировки выбором. Здесь дело в том, что результаты однократного измерения ненадежны. Нужно измерить
# производительность алгоритмов несколько раз подряд на одних и тех же данных. Можем получить такой результат:
# Быстрая сортировка — 0,21 миллисекунда
# Сортировка выбором — 0,12 миллисекунд
# Или даже такой:
# Быстрая сортировка — 0,16 миллисекунд
# Сортировка выбором — 0,17 миллисекунд
# Разброс может быть достаточно большим. Дело в том, что на производительность нашей программы влияет множество
# случайных факторов: другие запущенные программы на компьютере, режим энергосбережения и так далее.
# В работе алгоритмов много перечисленных тонкостей, поэтому сравнивать скорости довольно трудно. Чтобы справиться с
# этой трудностью, используем статистические методы. Будем запускать одну и ту же функцию много раз, а затем разделим
# общее время выполнения на количество запусков, чтобы вычислить среднее время выполнения:


def average_performance(f, count):
    start = datetime.now()
    for i in range(count):
        f
    end = datetime.now()
    return (end - start) / count


items = [86, 66, 44, 77, 56, 64, 76, 39, 32, 93, 33, 54, 63, 96, 5, 41, 20, 58, 55, 28]
print(average_performance(selection_sort(items[:]), 1))  # 0.1000000238418
print(average_performance(selection_sort(items[:]), 10))   # 0.0699999988079
# Возможно вы не знакомы с конструкцией items[:], которая встречается в этом коде. Она позволяет сделать копию массива
# items. Без копии мы при первом же вызове функции selectionSort упорядочим массив items, и последующие вызовы будут
# измерять скорость сортировки уже упорядоченного массива.
# У функции average_performance два параметра:
# - Функция, чью производительность мы хотим измерить.
# - Количество раз, когда мы хотим ее запустить.
# Мы видим, что среднее время выполнения может заметно отличаться от времени, измеренного один раз — на 30% в нашем
# случае. Значит ли это, что теперь у нас в руках есть надежный способ сравнения алгоритмов? Кажется, что да. Но мы пока
# так и не выяснили, почему быстрая сортировка такая медленная по сравнению с сортировкой выбором.
# Продолжим искать причину и сравним время выполнения разных сортировок на массиве из ста элементов:
items = [86, 66, 44, 77, 56, 64, 76, 39, 32, 93, 33, 54, 63, 96, 5, 41, 20, 58, 55, 28, 91, 81, 97, 24, 96, 33, 11,
         47, 18, 44, 95, 34, 52, 65, 18, 5, 30, 54, 67, 24, 13, 70, 62, 88, 18, 78, 72, 40, 10, 73, 27, 44, 46, 8, 1,
         49, 45, 98, 91, 70, 30, 48, 44, 52, 24, 39, 91, 22, 93, 30, 2, 85, 30, 34, 7, 82, 18, 87, 91, 37, 11, 93,
         74, 27, 15, 44, 81, 15, 74, 17, 53, 3, 67, 84, 78, 98, 6, 8, 90, 50]
print(average_performance(selection_sort(items[:]), 10))  # 0.60
print(average_performance(quick_sort(items[:]), 10))  # 0.19
# На большом массиве быстрая сортировка оказывается в три раза быстрее, чем сортировка выбором! Как такое может быть?
# Конечно, у этой странности есть объяснение, мы обсудим его чуть позже. Сейчас обратим внимание, что измерения скорости
# алгоритма на одних данных ничего не говорит об его скорости на других данных.
# Мы можем с большой точностью оценить время работы алгоритма на массиве из десяти элементов и при этом мы совершенно не
# представляем, какой окажется скорость того же алгоритма на массиве из ста тысяч элементов. Именно поэтому перед
# программистами встала задача — научиться оценивать скорость алгоритмов в целом.


# Оценка скорости алгоритмов «в целом».
# Идея оценки «в целом» пришла к нам из математики, где есть похожая задача — нужно оценивать порядок роста функций.
# Математики могут точно рассчитать скорость возрастания функции в любой точке, но эта информация может оказаться не
# очень полезной. Сравним графики двух функций:
# Кажется, что синяя функция больше, чем, красная. Но если посмотреть на те же графики в другом масштабе, картина
# изменится:
# Красная функция растет гораздо быстрее и почти сразу становится больше синей. С алгоритмами возникает та же проблема:
# на одном наборе данных первый алгоритм физически будет быстрее второго, на многих других наборах он может оказаться
# гораздо медленнее. Синяя функция на графике — это прямая линия, а красная — это парабола.
# Синие функции в математике принято называть линейными, а красные — квадратичными. Математики знают, что квадратичные
# функции растут быстрее линейных, а кубические — быстрее квадратичных.
# Алгоритмическая сложность тоже бывает линейной, квадратичной и кубической. Для нее характерна та же самая зависимость:
# алгоритмы с квадратичной сложностью в целом работают медленнее алгоритмов с линейной сложностью. Рассмотрим несколько
# алгоритмов и разберемся, как определять временную сложность.


# Линейная сложность.
# Чтобы определить временную сложность алгоритма, программисты ставят мысленный эксперимент. Предположим, что мы точно
# измерили время работы алгоритма на одном массиве, а потом увеличили этот массив в десять раз. Как увеличится время
# работы алгоритма? Если время работы алгоритма также увеличится в десять раз, то речь идет о линейной сложности — на
# графике она бы описывалась прямой линией.
# Типичный линейный алгоритм — поиск минимального элемента в массиве:
def get_minimum(items):
    minimum = items[0]
    for i in range(1, len(items)):
        if minimum > items[i]:
            minimum = items[i]
    return minimum
# Это простой алгоритм. Мы просматриваем элементы массива по одному и сравниваем с уже найденным. Если новый элемент
# оказывается меньше минимума, он становится новым минимумом. В самом начале в качестве минимума выбираем самый первый
# элемент массива с индексом 0. Функция состоит из двух смысловых элементов. Первый элемент — инициализация:
# minimum = items[0]
# Второй элемент — это цикл:
# for i in range(1, len(items)):
#     if minimum > items[i]:
#         minimum = items[i]
# Если в массиве 10 элементов, цикл выполнится 9 раз, если 100 элементов — 99 раз, если n элементов, цикл выполнится
# n - 1 раз. В итоге, для массива из n элементов функция выполнит n операций — одну операцию инициализации и n - 1
# операций в цикле. Если увеличить размер массива в 10 раз, то количество элементов будет равно 10 * n, и количество
# операций также будет равно 10 * n, то есть тоже вырастет в 10 раз.
# Такая линейная временная сложность обозначается O(n). Из-за того, что в записи используется большая буква O,
# она называется «нотация О-большое». Буква O появилась здесь не случайно. Это первая буква немецкого слова Ordnung,
# которое означает порядок. В математике, откуда пришло обозначение, оно относится к порядку роста функций.
# Какие еще алгоритмы имеют линейную временную сложность? Например, алгоритм вычисления среднего арифметического:


def get_average(items):
    sum = 0
    for i in range(len(items)):
        sum = sum + items[i]
    return sum / len(items)
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#
#

